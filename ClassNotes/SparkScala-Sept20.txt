
  Agenda (Spark using Scala)
  --------------------------
   -> Scala Refresher
   -> Spark - Basics & Architecture
   -> Spark Core API
	-> RDD - Transformations and Actions
	-> Spark Shared Variable
        -> Spark-Submit
   -> Spark SQL
	-> DataFrame Operations
	-> Integration with MySQL & Hive
	-> SQL Optimizations & Tuning
   -> Spark Streaming
	-> DStreams API (introduction)
	-> Structured Streaming

  Materials
  ---------
	=> PDF Presentations
	=> Code Modules
	=> Class Notes
	=> Github: https://github.com/ykanakaraju/sparkscala

  Scala
  -----
	
   -> Scala is Java based compiler language
        -> Scala compiles to Java byte code
	-> Interoperable with Java language
	
    -> Scala is multi-paradigm programming language	
	 -> Pure OOP language
         -> Functional programming language

    -> Pure OOP language
	 -> Scala does not have primitive and operator

   -> Scala Variables: immutables -> val
		       mutable    -> var

   -> Scala infers the type automatically based on the assigned value.

   -> Scala infix notation : 
		
	val j = i.+(10)  can be written in scala as:
	val j = i + 10

   -> Scala is a statically typed language
	-> The type of every object/variable is know at compile time. 
	-> Once assigned a type can not be changed. 

  Blocks
  ------

	-> One or more statements enclosed in { .. }
	    -> If there is only one statement/expression then you may omit the { .. }
	-> A block returns an ouput
	    -> The output is the value of the last statement that is executed in the block.
	-. Scala does not use "return" keyword

  Unit
  ----
	-> Is a class that represents 'no value'
        -> Printed as "()"  	

  Flow Control Statements
  -----------------------

   if..else
   ----------

	if (<boolean>) { ... }
	else if (<boolean>) { ... }
	else { ...}

	=> If statement in Scala, retruns a value

   match..case
   -----------
	
	 output = i match {
     		case 10 => "ten"
     		case 20 => "twenty"
     		case _ if (i % 2 == 0) => "even number"
     		case _  => "default output" 
  	}
  

   Scala Class Hierarchy
   ---------------------

	Any => AnyVal => Int, Long, Float, Double, Boolean, Unit, Byte, Char
            => AnyRef => String, <all other classes>


   Range
   -----
	Is a collection which store the starting value, end value and a step.

	Range(1, 10)       => 1,2,3,4,5,6,7,8,9
	Range(1, 10, 2)    => 1,3,5,7,9
	Range(100, 0, -20) => 100,80,60,40,20
	Range(1, 10, -2)   => Empty 

	1 to 10 by 2       => 1, 3, 5, 7, 9
	100 to 0 by -20	   => 100,80,60,40,20,0   ('to' returns Range.Inclusive)
        100 until 0 by -20 => 100,80,60,40,20,0 
	     
   Loops
   -----
   1. while

	var i = 0
   
   	while( i < 10 ) {
     	   println(s"i = $i")     
     	  i = i + 1     
   	}

   2. do while

	 do {
           println(s"i = $i")     
          i = i + 1     
        } while( i < 10 )

   3. foreach

	<collection>.foreach( fn )

	function "fn" is executes on all the objects of the collection.

	def f1(i: Int) = { println(i) }    
    	List(1,2,3,4,5,6,7,8,9).foreach( f1 )

   4. for 

	for( <generator(s)> ) {
        }

	for( x <- 1 to 10 by 2 ){
      		println(x)
    	}

	for( x <- 1 to 10 by 2; y <- 1 to 20 by 4){
      	    println(x, y)
        }

        for( x <- 1 to 10 by 2 if (x != 5); y <- 1 to 20 by 4 if (y > x)){
           println(x, y)
        }

        for comprehension: Collects the data looped by for loop using "yield" function and returns a collection.  

		val v1 = for( x <- 1 to 10 by 2 if (x != 5); y <- 1 to 20 by 4 if (y > x)) yield( (x, y) )
		println( v1 )

		Output:
		Vector((1,5), (1,9), (1,13), (1,17), (3,5), (3,9), (3,13), (3,17), (7,9), (7,13), (7,17), (9,13), (9,17))



   Interpolators
   --------------
      => Interpolator evaluates a string.

	1. 's' interpolator
		s"x = $x, x+1 = ${x+1}, y = $y"

        2. 'f' interpolator  => s interpolator + fromatting chars
		f"x = $x%1.1f, x+1 = ${x+1}, y = $y"

        3. 'raw' interpolator => will escape the escape chars

		val filePath = raw"E:\Spark\new\wordcount.txt"

  Exception Handling
  ------------------
	try {
	    // write you that could throw an exception. 
	}
	catch {		
	   case e1: FileNotFoundException => { .... }
           case e2: ArrayIndexOutOfBoundsException => { .... }
	   case _:Exception => { .... }
	}
	finally {
	    // write code that is always executed.
	}
       

   Getting started with Scala
   --------------------------

     1. Working in your vLab
	   => Follow the instructions on the attached document that you receive by email.
           => You log into a Ubuntu/CentOS VM
	   => You can launch Scala Shell & can start Scala IDE

      2. Installing Scala IDE on your personal machine. 

	  2.1 Scala IDE for eclipse

	  	=> Make sure you have Java 8 (jdk 1.8 or up) installed.

	  	=> Download and extract Scala IDE for eclispe from the following url link:
			http://scala-ide.org/download/sdk.html
	     	=> Nivagate inside the extracted folder (such as scala-SDK-4.7.0-vfinal-2.12-win32.win32.x86_64)
			and click in 'scala ide' icon to launch the IDE.

	  2.2 IntelliJ

		Instruction on how to install and setup IntelliJ for Scala are described here:
		https://docs.scala-lang.org/getting-started/index.html (near to 'Open hello-world project')

      3. Signup to Databricks community account
		=> https://www.databricks.com/try-databricks

      4. Online Scala Compilers
		https://scastie.scala-lang.org/



   Tuple
   ------
     => Tuple is an object that can hold multiple objects of different type
	-> A tuple with two objects is called a Pair

	 val t1 = (10, 10.5, "Hello")
   	 -> t1: (Int, Double, String) = (10,10.5,Hello)

	print( t1._1, t1._2, t1._3 )


   Methods
   -------
    -> Callable/reusable code block


	def add(a: Int, b: Int, c: Int) : Int = {
		a + b + c
	}

        -> Methods can be called by position
		val s = add(10, 20, 30)

        -> Methods can be called using named arguments
		val s = add(b=10, c=20, a=30)
  
	-> Method arguments can have default values.	
	
		def add(a: Int, b: Int = 0, c: Int = 0) : Int = {
			a + b + c
		}
  		val s = add(10, 20, 30)
		val s = add(10, 20)
		val s = add(10)

	-> Methods can have variable-lenght arguments
		-> Only one variable-lengh arg. is allowed and it should be the last argument.
		-> If can ot have default values when using variable-lengh arguments

		def add(a: Int, b: Int*) : Int = {
       			var s = a
       			for (i <- b) s += i
       			s
    		}   
    
    		val s = add(10, 20, 30, 40, 50)

       -> Methods can be called recursivly

		def factorial(n : Int) : Int = {
       		    if (n == 1) 1
       		    else n * factorial(n-1)
    		}

       -> Nested-methods
	
		def factorial2(i: Int): Int = {
      		   def fact(i: Int, accumulator: Int): Int = {
         		if (i <= 1)
            			accumulator
         		else
            			fact(i - 1, i * accumulator)
      		   }
      		   fact(i, 1)
   		}

       -> Methods can have multiple parameter lists

		def add(a: Int, b: Int)(c: List[Int]) = {
        		a + b + c.sum
     		}
     
     		val s = add(10, 20)( List(10,20,30) )

   Procedure
   ---------
	=> A procedure always returns Unit. 

		def box(name: String) {
      		   val line = "-" * name.length + "----"       
      		   println( line + "\n| " + name.toUpperCase + " |\n" + line )
                }

   Functions
   ---------
	=> In FP languages, function is treated as a literal (just like 10, "Hello", true)
	=> A function, by nature, is anonymous

	=> A function can be assigned to a variable
               val f1 = (a: Int, b: Int) => a + b
	
	=> A function can be passed as a parameter to another method/function

		def m1(a: Int, b: Int, f: (Int, Int) => Int ) = { a + b + f(a, b) }     
   		val x = m1(10, 20, (a, b) => a + b )

	=> A function/method can return a function as the final value.

		def compute(op: String) : (Int, Int) => Int = {
         		op match {
           			case "+" => (a: Int, b: Int) => a + b
           			case "-" => (a: Int, b: Int) => a - b
           			case "*" => (a: Int, b: Int) => a * b
           			case "/" => (a: Int, b: Int) => a / b
           			case _ => (a: Int, b: Int) => a % b
         		}
      		}
      
      		val f1 = compute("blah")     
            
      		println( f1, f1(100, 15) )

	
	Function Literal				Function Type
	--------------------------------------------------------------------
	(n: String) => n.toUpperCase			String => String
	(i: Int, j: Int) => i + j			(Int, Int) => Int
	(s: String, i: Int) => s * i			(String, Int) => String
	(S: String) => print(s)				String => Unit
	() => "Windows 10"				() => String
	(p: (Int, Int)) => p._1 + p._2			((Int, Int)) => Int
	(l: List[Int]) => l.length			List[Int] => Int



   Higher Order Functions
   ----------------------
       => Are functions/methods that take a function as an argument (or return function as a return value)
       => Operated on some collections
               <collection>.higher-order-fn( fn ) => <modifed-collection>
		
	  
    1. map	  	P: U => V
			map transforms the input elements by applying the function.
			input: N objects, output: N objects

		List(1,2,1,6,3,7,8,5,7,6,9,0,7,4).map( x => (x, x*x) )

    2. filter		P: U => Boolean
			Only those elements from the input collection for which the function returns true
			will be there in the output collection.
			input: N objects, output: <= N objects

		l1.filter(x => x.length > 51)

    3. flatMap		P: U => GenTraversableOnce[V]
			flatMap flattens the collection objects returned by the function.
			input: N objects, output: >= N objects

    		val words = l1.flatMap(s => s.split(" "))

     4. reduce  (reduceLeft/reduce & reduceRight)
			P: (U, U) => U
			Will reduce the entire input collection to one object of the same type
			by iterativly applying the function. 

	 	l1 => List(2,1,3,2,4,5,7,4)   => 4
		l1.reduceRight( (a, b) => a - b )

     5. sortWith	P: Binary sorting function

		t1.sortWith( (a, b) => a._2 > b._2 )
		words.sortWith( (a, b) => a(a.length - 1) < b(b.length - 1))

     6. groupBy		P: U => V
			Objects of the input collection are grouped based on the function output
			Returns scala.collection.immutable.Map[V,List[U]] where:
				each unique value of the fn output is the key (K)
				all objects of the collection that produvced the key forms the value (V)

			List[U].groupBy( U => V ) => List[ (V, Iterable[U]) ]

			words.groupBy( x => x ).toList.map(t => (t._1, t._2.length))

     7. foldLeft & foldRight	=> reduces the entire collection to a type that is different that the type of objects

			Two parameters as param-list
			
			1. zero-value : starting value of the type of output you want as output
			2. Sequence Function : is a function that iterativly merges all the objects of the 
			   collection with the zero-value. 

			List[U].foldLeft( (V, U) => V )  => V
	
				
		l1.foldRight( (0,0) )( (v, z) => (z._1 + v, z._2 + 1) )

   

   Wordcount Program
   ------------------
	val filePath = "E:\\Spark\\wordcount.txt"
     
     	val output = Source
                   .fromFile(filePath)
                   .getLines()
                   .toList
                   .flatMap(x => x.split(" "))
                   .groupBy( x => x )
                   .toList
                   .map( p => (p._1, p._2.length) ) 
                   .sortWith( (a, b) => a._2 > b._2 )
     
     	println( output )



  








 









